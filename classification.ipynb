{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a 1D CNN model to classify the synthetic ECG data and test the model on real data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "from synDataLoader import syn_mitbih, mixed_mitbih\n",
    "from DataLoader import mitbih_train, mitbih_test"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "mixed_ecg = mixed_mitbih(real_samples = 200, syn_samples = 800)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "syn_ecg = syn_mitbih(n_samples=800, reshape=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "real_ecg = mitbih_train(n_samples=200, oneD=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "real_test_ecg = mitbih_test(n_samples=500, oneD=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "from torch.utils import data\n",
    "syn_loader = data.DataLoader(syn_ecg, batch_size=32, num_workers=4, shuffle=True)\n",
    "real_loader = data.DataLoader(real_ecg, batch_size=32, num_workers=4, shuffle=True)\n",
    "mixed_loader = data.DataLoader(mixed_ecg, batch_size=32, num_workers=4, shuffle=True)\n",
    "test_real_loader = data.DataLoader(real_test_ecg, batch_size=32, num_workers=4, shuffle=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "#Define a simple CNN classifier \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ECG_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 64, 6)\n",
    "        self.conv2 = nn.Conv1d(64, 64, 6)\n",
    "        self.conv3 = nn.Conv1d(64, 64, 3)\n",
    "        self.dropout = nn.Dropout(p=0.5) \n",
    "        self.pool = nn.MaxPool1d(3)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(1152, 100)\n",
    "        self.fc2 = nn.Linear(100, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "def train(model, train_data_loader, test_data_loader, epochs, criterion, optimizer, filename=\"test_cm\"):\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "\n",
    "        for i, data in enumerate(train_data_loader):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.double()\n",
    "            labels = labels.long()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "        epoch_train_loss = total_loss / len(train_data_loader)\n",
    "        epoch_train_acc = correct / total\n",
    "        print(f'Epoch {epoch + 1}, train loss = {epoch_train_loss}, train acc = {epoch_train_acc}')\n",
    "\n",
    "        if (epoch+1) % 5 == 0:\n",
    "            _eval(model, test_data_loader, criterion, epoch)\n",
    "#             _eval_single_class(model, test_data_loader, criterion, epoch)\n",
    "            \n",
    "    _final_eval(model, test_data_loader, criterion, filename)\n",
    "\n",
    "    print('Finished Training and testing')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "def _eval(model, real_test_loader, criterion, epoch):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(real_test_loader):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.double()\n",
    "            labels = labels.long()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # print statistics\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_test_loss = total_loss / len(real_test_loader)\n",
    "        epoch_test_acc = correct / total\n",
    "    \n",
    "    print('=====================================================')\n",
    "    print(f'Epoch {epoch+1}, test loss = {epoch_test_loss}, test acc = {epoch_test_acc}')\n",
    "    print('=====================================================')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "classes = ['Non-Ectopic Beats', 'Superventrical Ectopic', 'Ventricular Beats', 'Unknown', 'Fusion Beats']\n",
    "classes_idx = ['1','2','3','4','5']\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "def _eval_single_class(model, real_test_loader, criterion, epoch):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(real_test_loader):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.double()\n",
    "            labels = labels.long()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # print statistics\n",
    "            total_loss += loss.item()\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            # collect the correct predictions for each class\n",
    "            for label, prediction in zip(labels, predictions):\n",
    "                if label == prediction:\n",
    "                    correct_pred[classes[label]] += 1\n",
    "                total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "    # print accuracy for each class\n",
    "    for classname, correct_count in correct_pred.items():\n",
    "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "        print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
    "                                                       accuracy))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def _final_eval(model, real_test_loader, criterion, filename=\"test_cm\"):\n",
    "    nb_classes = 5\n",
    "    predlist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
    "    lbllist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
    "    target_names = classes\n",
    "    y_preds = []\n",
    "    y_trues = []\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(real_test_loader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.double()\n",
    "            labels = labels.long()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            # Append batch prediction results\n",
    "            predlist=torch.cat([predlist,predictions.view(-1).cpu()])\n",
    "            lbllist=torch.cat([lbllist,labels.view(-1).cpu()])\n",
    "            \n",
    "            y_preds.append(predictions)\n",
    "            y_trues.append(labels)\n",
    "            \n",
    "    # Confusion matrix\n",
    "    cm=confusion_matrix(lbllist.numpy(), predlist.numpy())\n",
    "    print(cm)\n",
    "    cm_df = pd.DataFrame(cm,\n",
    "                     index = classes_idx, \n",
    "                     columns = classes_idx)\n",
    "    fig = plt.figure(figsize=(6.5,5))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='cubehelix_r')\n",
    "#     plt.title('ECG classification Accuracy')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout() # keeps labels from being cutoff when saving as pdf\n",
    "    plt.savefig(f'{filename}.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    class_accuracy = 100*cm.diagonal() / cm.sum(1)\n",
    "    print(class_accuracy)\n",
    "    \n",
    "    #print classification report \n",
    "    y_preds_flatten = [label for sublist in y_preds for label in sublist]\n",
    "    y_trues_flatten = [label for sublist in y_trues for label in sublist]\n",
    "    \n",
    "    print(classification_report(y_trues_flatten, y_preds_flatten, target_names=classes))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "source": [
    "# Define training hyperparameters\n",
    "import torch.optim as optim\n",
    "ECG_model = ECG_Net()\n",
    "ECG_model.double()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(ECG_model.parameters(), lr=0.0005, momentum=0.9)\n",
    "train(ECG_model, syn_loader, test_real_loader, 50, criterion, optimizer, filename='synthetic_data')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "source": [
    "# Define training hyperparameters\n",
    "import torch.optim as optim\n",
    "ECG_model = ECG_Net()\n",
    "ECG_model.double()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(ECG_model.parameters(), lr=0.0005, momentum=0.9)\n",
    "train(ECG_model, real_loader, test_real_loader, 50, criterion, optimizer, filename='real_data')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "# Define training hyperparameters\n",
    "import torch.optim as optim\n",
    "ECG_model = ECG_Net()\n",
    "ECG_model.double()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(ECG_model.parameters(), lr=0.0005, momentum=0.9)\n",
    "train(ECG_model, real_loader, test_real_loader, 50, criterion, optimizer, filename='real_data_small')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "import torch.optim as optim\n",
    "ECG_model = ECG_Net()\n",
    "ECG_model.double()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(ECG_model.parameters(), lr=0.0005, momentum=0.9)\n",
    "train(ECG_model, mixed_loader, test_real_loader, 50, criterion, optimizer, filename='mixed_data')"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
